{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MGP_3_Modelling_Var_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4h8TV6m3FNmT",
        "1A5hLlsKWp2Q",
        "hw0Y0ACdDcNy",
        "z-tHpAIdDf84",
        "PuvgIhMIHeWo",
        "lPO7UTO2Fysd",
        "y-XRCF_wO54m",
        "wH5PIdFPXNIY",
        "iMFMq_57Q-Rg"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFrsVJtQYGXb"
      },
      "source": [
        "# Movie Genre Prediction(MGP) using NLP\n",
        "*Hemansh Anand*\n",
        "\n",
        "---\n",
        "\n",
        "# Notebook 3: Modeling with Exp1_Var2\n",
        "\n",
        "The main purpose of this notebook is to fit the model using the train data and find out the best reults. We have first done scaling of the Data and then used OneVsRest with Logistic Regression,Stochastic Gradient Descent and MultinomialNB.\n",
        "\n",
        "**This notebook accomplishes two primary tasks:**\n",
        "\n",
        "1.   Fit and Export different models.\n",
        "2.   Discuss the best results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8TV6m3FNmT"
      },
      "source": [
        "### Import Libraraies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGwYAUi-bHXH"
      },
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "from ast import literal_eval\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut62AhZLBFO9"
      },
      "source": [
        "## Import the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j58kOBD8Gt21"
      },
      "source": [
        "Importing Train and Test dataframes from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1aItXN6Gdgr"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Colab Files/Movie Genre/Modified Datasets/train.csv', index_col=0)\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Files/Movie Genre/Modified Datasets/test.csv', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "kjOdfv2jGvz5",
        "outputId": "bb4f8552-977a-48d9-8db2-57a1647d2750"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>13th</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>17th</th>\n",
              "      <th>18</th>\n",
              "      <th>18th</th>\n",
              "      <th>19</th>\n",
              "      <th>1900</th>\n",
              "      <th>1920</th>\n",
              "      <th>1930</th>\n",
              "      <th>1936</th>\n",
              "      <th>1939</th>\n",
              "      <th>1940</th>\n",
              "      <th>1941</th>\n",
              "      <th>1942</th>\n",
              "      <th>1943</th>\n",
              "      <th>1944</th>\n",
              "      <th>1945</th>\n",
              "      <th>1950</th>\n",
              "      <th>1955</th>\n",
              "      <th>1959</th>\n",
              "      <th>1960</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>...</th>\n",
              "      <th>yearn</th>\n",
              "      <th>yellow</th>\n",
              "      <th>yet</th>\n",
              "      <th>york</th>\n",
              "      <th>yorker</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>youngster</th>\n",
              "      <th>youth</th>\n",
              "      <th>yu</th>\n",
              "      <th>yugoslavia</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zero</th>\n",
              "      <th>zombi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>gen_action</th>\n",
              "      <th>gen_adventure</th>\n",
              "      <th>gen_animation</th>\n",
              "      <th>gen_biography</th>\n",
              "      <th>gen_comedy</th>\n",
              "      <th>gen_crime</th>\n",
              "      <th>gen_documentary</th>\n",
              "      <th>gen_drama</th>\n",
              "      <th>gen_family</th>\n",
              "      <th>gen_fantasy</th>\n",
              "      <th>gen_film-noir</th>\n",
              "      <th>gen_history</th>\n",
              "      <th>gen_horror</th>\n",
              "      <th>gen_music</th>\n",
              "      <th>gen_musical</th>\n",
              "      <th>gen_mystery</th>\n",
              "      <th>gen_romance</th>\n",
              "      <th>gen_sci-fi</th>\n",
              "      <th>gen_sport</th>\n",
              "      <th>gen_thriller</th>\n",
              "      <th>gen_war</th>\n",
              "      <th>gen_western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.269463</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5473 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000   10  100  ...  gen_sport  gen_thriller  gen_war  gen_western\n",
              "0  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "1  0.0  0.0  0.0  0.0  ...          0             1        0            0\n",
              "2  0.0  0.0  0.0  0.0  ...          0             0        1            0\n",
              "3  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "4  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "\n",
              "[5 rows x 5473 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A5hLlsKWp2Q"
      },
      "source": [
        "### Splitting Data into X and y\n",
        "\n",
        "\n",
        "\n",
        "* X contains the features\n",
        "*   y contains the genres\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPa6GP6ZGFQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9bccaf-e417-4eb0-b049-f5a0447f1f76"
      },
      "source": [
        "cols = list(train.columns.values)\n",
        "genre_cols = cols[-22:]\n",
        "print(len(genre_cols))\n",
        "print(genre_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "['gen_action', 'gen_adventure', 'gen_animation', 'gen_biography', 'gen_comedy', 'gen_crime', 'gen_documentary', 'gen_drama', 'gen_family', 'gen_fantasy', 'gen_film-noir', 'gen_history', 'gen_horror', 'gen_music', 'gen_musical', 'gen_mystery', 'gen_romance', 'gen_sci-fi', 'gen_sport', 'gen_thriller', 'gen_war', 'gen_western']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8ij0yyh8ps"
      },
      "source": [
        "X_train = train[train.columns[~train.columns.isin(genre_cols)]]\n",
        "y_train = train[train.columns[ train.columns.isin(genre_cols)]]\n",
        "\n",
        "X_test = test[test.columns[~test.columns.isin(genre_cols)]]\n",
        "y_test = test[test.columns[ test.columns.isin(genre_cols)]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1zy82LTXft8"
      },
      "source": [
        "# Experiment Setup 2 Scaling the Data\n",
        "\n",
        "\n",
        "*   Exp_2_Var_1 Standard Scaler\n",
        "*   Exp_2_Var_2 Min Max Scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_d84FANXk8z"
      },
      "source": [
        "## Exp_2_Var_1 Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q8FPHNuXSvV",
        "outputId": "1ce68996-03d1-42b0-f495-52b738eaea2a"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "std_scaler = StandardScaler().fit(X_train)\n",
        "X_train_std = std_scaler.transform(X_train)\n",
        "X_test_std = std_scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(std_scaler, 'standard_scaler.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['standard_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvjqfkttxf9"
      },
      "source": [
        "## Exp_3 Different Models under Standard Scaling\n",
        "\n",
        "\n",
        "\n",
        "*   Exp_3_Var_1 Logistic Regression\n",
        "*   Exp_3_Var_2 Stochastic Gradient Descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw0Y0ACdDcNy"
      },
      "source": [
        "### Exp_3_Var_1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwWdV6k1i1HM"
      },
      "source": [
        "model_1 = OneVsRestClassifier(LogisticRegression(random_state=123, max_iter=3000, C=1, n_jobs=-1), n_jobs=-1).fit(X_train_std, y_train)\n",
        "    \n",
        "# export the mode;\n",
        "joblib.dump(model_1, '/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/model_1.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_1 = model_1.predict(X_train_std)\n",
        "y_pred_model_1 = model_1.predict(X_test_std)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_1, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_1, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_1, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_1, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_1, average='weighted')\n",
        "test_f1_score = f1_score(y_test, y_pred_model_1, average='weighted')\n",
        "\n",
        "train_classification_report= classification_report(y_test, y_pred_model_1)\n",
        "print(train_classification_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-tHpAIdDf84"
      },
      "source": [
        "### Exp_3_Var_2 Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcKpqyJTlDVM"
      },
      "source": [
        "model_2 = OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', random_state=123, alpha=1, n_jobs=-1, max_iter=3000), n_jobs=-1).fit(X_train_std, y_train)\n",
        "\n",
        "# export the model\n",
        "joblib.dump(model_2, '/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/model_2.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_2 = model_2.predict(X_train_std)\n",
        "y_pred_model_2 = model_2.predict(X_test_std)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_2, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_2, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_2, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_2, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_2, average='weighted')\n",
        "test_f1_score = f1_score(y_test, y_pred_model_2, average='weighted')\n",
        "\n",
        "# Classification Report\n",
        "test_classification_report= classification_report(y_test, y_pred_model_2)\n",
        "print(test_classification_report)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7CSOZq3Xv95"
      },
      "source": [
        "## Exp_2_Var_2 Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC0BGOZqGFQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba995a1-008a-4bfc-ac6c-d56638a91476"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "mima_scaler = MinMaxScaler().fit(X_train)\n",
        "X_train_mima = mima_scaler.transform(X_train)\n",
        "X_test_mima = mima_scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(mima_scaler, 'mima_scaler.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mima_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v92d-aGnuIBv"
      },
      "source": [
        "## Exp_4 Different Models under Min-Max Scaling\n",
        "\n",
        "\n",
        "\n",
        "*   Exp_4_Var_1 Logistic Regression\n",
        "*   Exp_4_Var_2 Stochastic Gradient Descent\n",
        "*   Exp_4_Var_3 Multinomial Naive Bayes\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuvgIhMIHeWo"
      },
      "source": [
        "### Exp_4_Var_1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9SuykcSYYXJ",
        "outputId": "0e766ebc-0cf3-45ef-817d-cc4e59213137"
      },
      "source": [
        "model_4 = OneVsRestClassifier(LogisticRegression(random_state=123, max_iter=3000, C=1, n_jobs=-1), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "    \n",
        "# export the model\n",
        "joblib.dump(model_4, '/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/model_4.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_4 = model_4.predict(X_train_mima)\n",
        "y_pred_model_4 = model_4.predict(X_test_mima)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_4, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_4, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_4, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_4, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_4, average='weighted')\n",
        "test_f1_score = f1_score(y_test, y_pred_model_4, average='weighted')\n",
        "\n",
        "train_classification_report= classification_report(y_test, y_pred_model_4)\n",
        "print(train_classification_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.6398425905854497\n",
            "Test Recall Score: 0.49018728830444314\n",
            "Train Precision Score: 0.8694203140770593\n",
            "Test Precision Score: 0.6891000561352323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.48      0.57      1404\n",
            "           1       0.64      0.32      0.43       862\n",
            "           2       0.51      0.13      0.21       232\n",
            "           3       0.62      0.19      0.29       392\n",
            "           4       0.69      0.58      0.63      2702\n",
            "           5       0.70      0.44      0.54      1208\n",
            "           6       0.88      0.50      0.64       357\n",
            "           7       0.71      0.76      0.73      4137\n",
            "           8       0.61      0.18      0.27       446\n",
            "           9       0.61      0.26      0.37       564\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.61      0.21      0.32       330\n",
            "          12       0.80      0.55      0.65      1019\n",
            "          13       0.85      0.31      0.46       494\n",
            "          14       0.57      0.09      0.15       227\n",
            "          15       0.53      0.23      0.32       686\n",
            "          16       0.65      0.43      0.52      1699\n",
            "          17       0.82      0.45      0.58       617\n",
            "          18       0.85      0.34      0.49       219\n",
            "          19       0.63      0.47      0.54      1847\n",
            "          20       0.83      0.43      0.57       384\n",
            "          21       0.90      0.31      0.46       169\n",
            "\n",
            "   micro avg       0.70      0.49      0.58     20076\n",
            "   macro avg       0.67      0.35      0.44     20076\n",
            "weighted avg       0.69      0.49      0.56     20076\n",
            " samples avg       0.68      0.54      0.56     20076\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPO7UTO2Fysd"
      },
      "source": [
        "### Exp_4_Var_2 Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6vGqDw4irDC",
        "outputId": "277f6bae-91dd-422c-ad2f-36c6c479c5fb"
      },
      "source": [
        "model_6 = OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', random_state=123, alpha=1, n_jobs=-1, max_iter=3000), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "\n",
        "# export the model\n",
        "joblib.dump(model_6, '/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/model_6.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_6 = model_6.predict(X_train_mima)\n",
        "y_pred_model_6 = model_6.predict(X_test_mima)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_6, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_6, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_6, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_6, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_6, average='weighted')\n",
        "test_f1_score = f1_score(y_test, y_pred_model_6, average='weighted')\n",
        "\n",
        "# Classification Report\n",
        "test_classification_report= classification_report(y_test, y_pred_model_6)\n",
        "print(test_classification_report)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.21028497106935018\n",
            "Test Recall Score: 0.20606694560669456\n",
            "Train Precision Score: 0.11770022503020618\n",
            "Test Precision Score: 0.11350006044133876\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1404\n",
            "           1       0.00      0.00      0.00       862\n",
            "           2       0.00      0.00      0.00       232\n",
            "           3       0.00      0.00      0.00       392\n",
            "           4       0.00      0.00      0.00      2702\n",
            "           5       0.00      0.00      0.00      1208\n",
            "           6       0.00      0.00      0.00       357\n",
            "           7       0.55      1.00      0.71      4137\n",
            "           8       0.00      0.00      0.00       446\n",
            "           9       0.00      0.00      0.00       564\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.00      0.00      0.00       330\n",
            "          12       0.00      0.00      0.00      1019\n",
            "          13       0.00      0.00      0.00       494\n",
            "          14       0.00      0.00      0.00       227\n",
            "          15       0.00      0.00      0.00       686\n",
            "          16       0.00      0.00      0.00      1699\n",
            "          17       0.00      0.00      0.00       617\n",
            "          18       0.00      0.00      0.00       219\n",
            "          19       0.00      0.00      0.00      1847\n",
            "          20       0.00      0.00      0.00       384\n",
            "          21       0.00      0.00      0.00       169\n",
            "\n",
            "   micro avg       0.55      0.21      0.30     20076\n",
            "   macro avg       0.03      0.05      0.03     20076\n",
            "weighted avg       0.11      0.21      0.15     20076\n",
            " samples avg       0.55      0.24      0.32     20076\n",
            "\n",
            "CPU times: user 6.56 s, sys: 6.1 s, total: 12.7 s\n",
            "Wall time: 31.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-XRCF_wO54m"
      },
      "source": [
        "### Exp_4_Var_3 Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qztN9VfwnFN4",
        "outputId": "c7c82948-71c4-4bd4-baae-b641e15385ce"
      },
      "source": [
        "model_7 = OneVsRestClassifier(MultinomialNB(alpha=1), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "\n",
        "# export the model\n",
        "joblib.dump(model_7, f'/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/model_7.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_7 = model_7.predict(X_train_mima)\n",
        "y_pred_model_7 = model_7.predict(X_test_mima)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_7, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_7, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_7, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "\n",
        "test_f1_score = f1_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "train_classification_report= classification_report(y_test, y_pred_model_7)\n",
        "print(train_classification_report)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.622284103983592\n",
            "Test Recall Score: 0.5328750747160789\n",
            "Train Precision Score: 0.7240758473671053\n",
            "Test Precision Score: 0.6524731443418311\n",
            "Train F1 Score: 0.6590790049701707\n",
            "Test F1 Score: 0.5738608522714271\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.56      0.59      1404\n",
            "           1       0.55      0.41      0.47       862\n",
            "           2       0.33      0.12      0.18       232\n",
            "           3       0.47      0.31      0.37       392\n",
            "           4       0.69      0.61      0.65      2702\n",
            "           5       0.66      0.50      0.57      1208\n",
            "           6       0.68      0.61      0.64       357\n",
            "           7       0.72      0.78      0.75      4137\n",
            "           8       0.64      0.17      0.26       446\n",
            "           9       0.55      0.30      0.39       564\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.44      0.34      0.39       330\n",
            "          12       0.76      0.59      0.66      1019\n",
            "          13       0.79      0.29      0.42       494\n",
            "          14       0.56      0.04      0.07       227\n",
            "          15       0.54      0.25      0.34       686\n",
            "          16       0.61      0.46      0.53      1699\n",
            "          17       0.67      0.54      0.60       617\n",
            "          18       0.82      0.28      0.42       219\n",
            "          19       0.63      0.53      0.57      1847\n",
            "          20       0.68      0.56      0.61       384\n",
            "          21       0.91      0.37      0.52       169\n",
            "\n",
            "   micro avg       0.66      0.53      0.59     20076\n",
            "   macro avg       0.61      0.39      0.45     20076\n",
            "weighted avg       0.65      0.53      0.57     20076\n",
            " samples avg       0.67      0.59      0.58     20076\n",
            "\n",
            "CPU times: user 28.6 s, sys: 9.08 s, total: 37.7 s\n",
            "Wall time: 40.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf7GuGH-vkcH"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WruK0mSIwI-W"
      },
      "source": [
        "Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zHcEd6ctwIKH",
        "outputId": "407eb0f1-6a58-4518-8c76-6a0a8c1070ee"
      },
      "source": [
        "results_std = pd.read_csv('/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/Results/Standard Scaler.csv', index_col=0)\n",
        "results_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Precission Score</th>\n",
              "      <th>Test Recall Score</th>\n",
              "      <th>Train F1 Score</th>\n",
              "      <th>Train Precission Score</th>\n",
              "      <th>Train Recall Score</th>\n",
              "      <th>Test F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.513606</td>\n",
              "      <td>0.527496</td>\n",
              "      <td>0.520458</td>\n",
              "      <td>0.916105</td>\n",
              "      <td>0.899735</td>\n",
              "      <td>0.907846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.741086</td>\n",
              "      <td>0.274856</td>\n",
              "      <td>0.400991</td>\n",
              "      <td>0.800719</td>\n",
              "      <td>0.306948</td>\n",
              "      <td>0.443778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test Precission Score  ...  Test F1 Score\n",
              "Logistic Regression               0.513606  ...       0.907846\n",
              "SGD                               0.741086  ...       0.443778\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns9s15MZwMUO"
      },
      "source": [
        "Min Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "RERZGoItvmkj",
        "outputId": "004c5a9e-c62b-4c6e-f4e3-933d04f74eb9"
      },
      "source": [
        "results_mima = pd.read_csv('/content/drive/MyDrive/Colab Files/Movie Genre/Final Trained Models/Results/MinMax Scaler.csv', index_col=0)\n",
        "results_mima"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Precission Score</th>\n",
              "      <th>Test Recall Score</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Train Precission Score</th>\n",
              "      <th>Train Recall Score</th>\n",
              "      <th>Train F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.689100</td>\n",
              "      <td>0.490187</td>\n",
              "      <td>0.572868</td>\n",
              "      <td>0.869420</td>\n",
              "      <td>0.639843</td>\n",
              "      <td>0.737171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.113500</td>\n",
              "      <td>0.206067</td>\n",
              "      <td>0.146377</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>0.210285</td>\n",
              "      <td>0.150925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MNB</th>\n",
              "      <td>0.652473</td>\n",
              "      <td>0.532875</td>\n",
              "      <td>0.586641</td>\n",
              "      <td>0.724076</td>\n",
              "      <td>0.622284</td>\n",
              "      <td>0.669332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test Precission Score  ...  Train F1 Score\n",
              "Logistic Regression               0.689100  ...        0.737171\n",
              "SGD                               0.113500  ...        0.150925\n",
              "MNB                               0.652473  ...        0.669332\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zflN_t1W-fy"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "After comparing all the models above with their respective scores, it was found that Min Max scaling is better than Standard Scaling for our dataset.\n",
        "\n",
        "Among the models trained after Min Max scaling, Stochastic Gradient Descent performed the worst. Multinomial Naive Bayes and Logistic Regression performed the equally good and I would like to try some hyperparameter tuning on both of them to find the better model."
      ]
    }
  ]
}