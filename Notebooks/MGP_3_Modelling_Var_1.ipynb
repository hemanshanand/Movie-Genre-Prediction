{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MGP_3_Modelling_Var_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4h8TV6m3FNmT",
        "1A5hLlsKWp2Q",
        "hw0Y0ACdDcNy",
        "z-tHpAIdDf84",
        "PuvgIhMIHeWo",
        "lPO7UTO2Fysd",
        "y-XRCF_wO54m",
        "wH5PIdFPXNIY",
        "iMFMq_57Q-Rg"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmJsW7oqPoUD"
      },
      "source": [
        "# Movie Genre Prediction(MGP) using NLP\n",
        "*Hemansh Anand*\n",
        "\n",
        "---\n",
        "\n",
        "# Notebook 3: Modeling with Exp1_Var1\n",
        "\n",
        "The main purpose of this notebook is to fit the model using the train data and find out the best reults. We have first done scaling of the Data and then used OneVsRest with Logistic Regression,Stochastic Gradient Descent and MultinomialNB.\n",
        "\n",
        "**This notebook accomplishes two primary tasks:**\n",
        "\n",
        "1.   Fit and Export different models.\n",
        "2.   Discuss the best results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8TV6m3FNmT"
      },
      "source": [
        "### Import Libraraies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGwYAUi-bHXH"
      },
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "from ast import literal_eval\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut62AhZLBFO9"
      },
      "source": [
        "## Import the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j58kOBD8Gt21"
      },
      "source": [
        "Importing Train and Test dataframes from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1aItXN6Gdgr"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Colab Files/MGP/Datasets/Experiment Setup 1/train_min_max.csv', index_col=0)\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Files/MGP/Datasets/Experiment Setup 1/test_min_max.csv', index_col=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "kjOdfv2jGvz5",
        "outputId": "c64ae25b-4ab5-4c06-909b-4b81b5f4e4f3"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>12</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>1970</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abduct</th>\n",
              "      <th>abil</th>\n",
              "      <th>abl</th>\n",
              "      <th>abus</th>\n",
              "      <th>accept</th>\n",
              "      <th>accid</th>\n",
              "      <th>accident</th>\n",
              "      <th>accompani</th>\n",
              "      <th>account</th>\n",
              "      <th>accus</th>\n",
              "      <th>achiev</th>\n",
              "      <th>across</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>adapt</th>\n",
              "      <th>addict</th>\n",
              "      <th>adopt</th>\n",
              "      <th>adult</th>\n",
              "      <th>advanc</th>\n",
              "      <th>adventur</th>\n",
              "      <th>advic</th>\n",
              "      <th>affair</th>\n",
              "      <th>affect</th>\n",
              "      <th>africa</th>\n",
              "      <th>african</th>\n",
              "      <th>...</th>\n",
              "      <th>worker</th>\n",
              "      <th>world</th>\n",
              "      <th>worri</th>\n",
              "      <th>wors</th>\n",
              "      <th>worst</th>\n",
              "      <th>would</th>\n",
              "      <th>wound</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>written</th>\n",
              "      <th>wrong</th>\n",
              "      <th>year</th>\n",
              "      <th>yet</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youth</th>\n",
              "      <th>zombi</th>\n",
              "      <th>gen_action</th>\n",
              "      <th>gen_adventure</th>\n",
              "      <th>gen_animation</th>\n",
              "      <th>gen_biography</th>\n",
              "      <th>gen_comedy</th>\n",
              "      <th>gen_crime</th>\n",
              "      <th>gen_documentary</th>\n",
              "      <th>gen_drama</th>\n",
              "      <th>gen_family</th>\n",
              "      <th>gen_fantasy</th>\n",
              "      <th>gen_film-noir</th>\n",
              "      <th>gen_history</th>\n",
              "      <th>gen_horror</th>\n",
              "      <th>gen_music</th>\n",
              "      <th>gen_musical</th>\n",
              "      <th>gen_mystery</th>\n",
              "      <th>gen_romance</th>\n",
              "      <th>gen_sci-fi</th>\n",
              "      <th>gen_sport</th>\n",
              "      <th>gen_thriller</th>\n",
              "      <th>gen_war</th>\n",
              "      <th>gen_western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.151140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386844</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.127585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1643 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   000   10   12   15  ...  gen_sport  gen_thriller  gen_war  gen_western\n",
              "0  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "1  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "2  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "3  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "4  0.0  0.0  0.0  0.0  ...          0             0        0            0\n",
              "\n",
              "[5 rows x 1643 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A5hLlsKWp2Q"
      },
      "source": [
        "### Splitting Data into X and y\n",
        "\n",
        "\n",
        "\n",
        "* X contains the features\n",
        "*   y contains the genres\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPa6GP6ZGFQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0729cd92-979b-4eaf-b12d-2f9c17bc4f98"
      },
      "source": [
        "cols = list(train.columns.values)\n",
        "genre_cols = cols[-22:]\n",
        "print(len(genre_cols))\n",
        "print(genre_cols)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "['gen_action', 'gen_adventure', 'gen_animation', 'gen_biography', 'gen_comedy', 'gen_crime', 'gen_documentary', 'gen_drama', 'gen_family', 'gen_fantasy', 'gen_film-noir', 'gen_history', 'gen_horror', 'gen_music', 'gen_musical', 'gen_mystery', 'gen_romance', 'gen_sci-fi', 'gen_sport', 'gen_thriller', 'gen_war', 'gen_western']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8ij0yyh8ps"
      },
      "source": [
        "X_train = train[train.columns[~train.columns.isin(genre_cols)]]\n",
        "y_train = train[train.columns[ train.columns.isin(genre_cols)]]\n",
        "\n",
        "X_test = test[test.columns[~test.columns.isin(genre_cols)]]\n",
        "y_test = test[test.columns[ test.columns.isin(genre_cols)]]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1zy82LTXft8"
      },
      "source": [
        "# Experiment Setup 2 Scaling the Data\n",
        "\n",
        "\n",
        "*   Exp_2_Var_1 Standard Scaler\n",
        "*   Exp_2_Var_2 Min Max Scaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_d84FANXk8z"
      },
      "source": [
        "## Exp_2_Var_1 Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q8FPHNuXSvV",
        "outputId": "c7239dff-dae4-4637-ee33-8b7a1b272aab"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "std_scaler = StandardScaler().fit(X_train)\n",
        "X_train_std = std_scaler.transform(X_train)\n",
        "X_test_std = std_scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(std_scaler, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/Scalers/standard_scaler.pkl')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/Scalers/standard_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvjqfkttxf9"
      },
      "source": [
        "## Exp_3 Different Models under Standard Scaling\n",
        "\n",
        "\n",
        "\n",
        "*   Exp_3_Var_1 Logistic Regression\n",
        "*   Exp_3_Var_2 Stochastic Gradient Descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw0Y0ACdDcNy"
      },
      "source": [
        "### Exp_3_Var_1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwWdV6k1i1HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06d1026-ca11-435a-e1c3-7dcefbc29ba7"
      },
      "source": [
        "model_1 = OneVsRestClassifier(LogisticRegression(random_state=123, max_iter=3000, C=1, n_jobs=-1), n_jobs=-1).fit(X_train_std, y_train)\n",
        "    \n",
        "# export the model\n",
        "joblib.dump(model_1, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/logreg.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_1 = model_1.predict(X_train_std)\n",
        "y_pred_model_1 = model_1.predict(X_test_std)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_1, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_1, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_1, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_1, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_1, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "test_f1_score = f1_score(y_test, y_pred_model_1, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "train_classification_report= classification_report(y_test, y_pred_model_1)\n",
        "print(train_classification_report)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.618053935131171\n",
            "Test Recall Score: 0.5011467889908257\n",
            "Train Precision Score: 0.7651395078018712\n",
            "Test Precision Score: 0.5943196500485064\n",
            "Train F1 Score: 0.6770202480236456\n",
            "Test F1 Score: 0.5389817539871439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.44      0.51      1349\n",
            "           1       0.56      0.36      0.44       867\n",
            "           2       0.23      0.25      0.24       258\n",
            "           3       0.37      0.27      0.31       376\n",
            "           4       0.65      0.55      0.60      2650\n",
            "           5       0.65      0.45      0.53      1240\n",
            "           6       0.48      0.60      0.53       334\n",
            "           7       0.71      0.75      0.73      4197\n",
            "           8       0.39      0.29      0.33       483\n",
            "           9       0.48      0.28      0.35       600\n",
            "          10       0.25      0.20      0.22        81\n",
            "          11       0.32      0.28      0.30       351\n",
            "          12       0.67      0.54      0.60      1003\n",
            "          13       0.54      0.38      0.45       465\n",
            "          14       0.17      0.18      0.17       219\n",
            "          15       0.46      0.28      0.35       685\n",
            "          16       0.62      0.44      0.51      1656\n",
            "          17       0.60      0.48      0.53       648\n",
            "          18       0.40      0.49      0.44       199\n",
            "          19       0.61      0.46      0.53      1833\n",
            "          20       0.44      0.50      0.47       395\n",
            "          21       0.42      0.49      0.45       167\n",
            "\n",
            "   micro avg       0.60      0.50      0.54     20056\n",
            "   macro avg       0.48      0.41      0.44     20056\n",
            "weighted avg       0.59      0.50      0.54     20056\n",
            " samples avg       0.61      0.55      0.54     20056\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-tHpAIdDf84"
      },
      "source": [
        "### Exp_3_Var_2 Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcKpqyJTlDVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0c2fd7-153e-4939-e5df-4f01fd50c933"
      },
      "source": [
        "model_2 = OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', random_state=123, alpha=1, n_jobs=-1, max_iter=3000), n_jobs=-1).fit(X_train_std, y_train)\n",
        "\n",
        "# export the model\n",
        "joblib.dump(model_2, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/SGD.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_2 = model_2.predict(X_train_std)\n",
        "y_pred_model_2 = model_2.predict(X_test_std)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_2, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_2, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_2, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_2, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_2, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "test_f1_score = f1_score(y_test, y_pred_model_2, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "test_classification_report= classification_report(y_test, y_pred_model_2)\n",
        "print(test_classification_report)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.22930764358811961\n",
            "Test Recall Score: 0.21604507379337853\n",
            "Train Precision Score: 0.764186259886078\n",
            "Test Precision Score: 0.713901988503582\n",
            "Train F1 Score: 0.24904694944436337\n",
            "Test F1 Score: 0.23355985891861222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.03      0.06      1349\n",
            "           1       0.00      0.00      0.00       867\n",
            "           2       0.00      0.00      0.00       258\n",
            "           3       0.00      0.00      0.00       376\n",
            "           4       0.84      0.21      0.34      2650\n",
            "           5       0.84      0.05      0.10      1240\n",
            "           6       1.00      0.03      0.06       334\n",
            "           7       0.69      0.82      0.75      4197\n",
            "           8       0.00      0.00      0.00       483\n",
            "           9       1.00      0.00      0.00       600\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.00      0.00      0.00       351\n",
            "          12       0.97      0.07      0.13      1003\n",
            "          13       1.00      0.01      0.02       465\n",
            "          14       0.00      0.00      0.00       219\n",
            "          15       0.50      0.00      0.00       685\n",
            "          16       0.94      0.01      0.02      1656\n",
            "          17       0.97      0.05      0.09       648\n",
            "          18       0.00      0.00      0.00       199\n",
            "          19       0.83      0.05      0.09      1833\n",
            "          20       0.92      0.03      0.06       395\n",
            "          21       0.00      0.00      0.00       167\n",
            "\n",
            "   micro avg       0.72      0.22      0.33     20056\n",
            "   macro avg       0.52      0.06      0.08     20056\n",
            "weighted avg       0.71      0.22      0.23     20056\n",
            " samples avg       0.53      0.27      0.34     20056\n",
            "\n",
            "CPU times: user 3.2 s, sys: 2.53 s, total: 5.73 s\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7CSOZq3Xv95"
      },
      "source": [
        "## Exp_2_Var_2 Min-Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC0BGOZqGFQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4c37db-7e71-4366-98dd-b40e181bc9c8"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "mima_scaler = MinMaxScaler().fit(X_train)\n",
        "X_train_mima = mima_scaler.transform(X_train)\n",
        "X_test_mima = mima_scaler.transform(X_test)\n",
        "\n",
        "joblib.dump(mima_scaler, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/Scalers/mima_scaler.pkl')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/Scalers/mima_scaler.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v92d-aGnuIBv"
      },
      "source": [
        "## Exp_4 Different Models under Min-Max Scaling\n",
        "\n",
        "\n",
        "\n",
        "*   Exp_4_Var_1 Logistic Regression\n",
        "*   Exp_4_Var_2 Stochastic Gradient Descent\n",
        "*   Exp_4_Var_3 Multinomial Naive Bayes\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuvgIhMIHeWo"
      },
      "source": [
        "### Exp_4_Var_1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9SuykcSYYXJ",
        "outputId": "f551d90d-a4c1-436b-f016-454935101e75"
      },
      "source": [
        "model_4 = OneVsRestClassifier(LogisticRegression(random_state=123, max_iter=3000, C=1, n_jobs=-1), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "    \n",
        "# export the model\n",
        "joblib.dump(model_4, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/logreg_mima.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_4 = model_4.predict(X_train_mima)\n",
        "y_pred_model_4 = model_4.predict(X_test_mima)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_4, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_4, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_4, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_4, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_4, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "test_f1_score = f1_score(y_test, y_pred_model_4, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "train_classification_report= classification_report(y_test, y_pred_model_4)\n",
        "print(train_classification_report)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.5261342044734825\n",
            "Test Recall Score: 0.4624052652572796\n",
            "Train Precision Score: 0.7780862290973529\n",
            "Test Precision Score: 0.6777482104217563\n",
            "Train F1 Score: 0.6053594198166531\n",
            "Test F1 Score: 0.530830645439008\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50      1349\n",
            "           1       0.65      0.30      0.41       867\n",
            "           2       0.50      0.07      0.12       258\n",
            "           3       0.61      0.15      0.24       376\n",
            "           4       0.67      0.54      0.59      2650\n",
            "           5       0.70      0.41      0.52      1240\n",
            "           6       0.87      0.48      0.62       334\n",
            "           7       0.72      0.76      0.74      4197\n",
            "           8       0.66      0.16      0.26       483\n",
            "           9       0.63      0.20      0.30       600\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.58      0.15      0.24       351\n",
            "          12       0.76      0.49      0.60      1003\n",
            "          13       0.77      0.31      0.44       465\n",
            "          14       0.68      0.09      0.15       219\n",
            "          15       0.53      0.23      0.32       685\n",
            "          16       0.66      0.42      0.51      1656\n",
            "          17       0.78      0.41      0.54       648\n",
            "          18       0.77      0.36      0.49       199\n",
            "          19       0.63      0.44      0.52      1833\n",
            "          20       0.74      0.44      0.55       395\n",
            "          21       0.87      0.29      0.43       167\n",
            "\n",
            "   micro avg       0.69      0.46      0.55     20056\n",
            "   macro avg       0.66      0.32      0.41     20056\n",
            "weighted avg       0.68      0.46      0.53     20056\n",
            " samples avg       0.67      0.52      0.54     20056\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPO7UTO2Fysd"
      },
      "source": [
        "### Exp_4_Var_2 Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6vGqDw4irDC",
        "outputId": "27daef67-c19b-4cef-d079-8ca7961aa933"
      },
      "source": [
        "model_6 = OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', random_state=123, alpha=1, n_jobs=-1, max_iter=3000), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "\n",
        "# EXPORT THE MODEL\n",
        "joblib.dump(model_6, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/sgd_mima.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_6 = model_6.predict(X_train_mima)\n",
        "y_pred_model_6 = model_6.predict(X_test_mima)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_6, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_6, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_6, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_6, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_6, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "test_f1_score = f1_score(y_test, y_pred_model_6, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "test_classification_report= classification_report(y_test, y_pred_model_6)\n",
        "print(test_classification_report)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.20922364078802627\n",
            "Test Recall Score: 0.20926406063023534\n",
            "Train Precision Score: 0.11655724327928345\n",
            "Test Precision Score: 0.11691710096713227\n",
            "Train F1 Score: 0.14971124453127138\n",
            "Test F1 Score: 0.15001815056197756\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1349\n",
            "           1       0.00      0.00      0.00       867\n",
            "           2       0.00      0.00      0.00       258\n",
            "           3       0.00      0.00      0.00       376\n",
            "           4       0.00      0.00      0.00      2650\n",
            "           5       0.00      0.00      0.00      1240\n",
            "           6       0.00      0.00      0.00       334\n",
            "           7       0.56      1.00      0.72      4197\n",
            "           8       0.00      0.00      0.00       483\n",
            "           9       0.00      0.00      0.00       600\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.00      0.00      0.00       351\n",
            "          12       0.00      0.00      0.00      1003\n",
            "          13       0.00      0.00      0.00       465\n",
            "          14       0.00      0.00      0.00       219\n",
            "          15       0.00      0.00      0.00       685\n",
            "          16       0.00      0.00      0.00      1656\n",
            "          17       0.00      0.00      0.00       648\n",
            "          18       0.00      0.00      0.00       199\n",
            "          19       0.00      0.00      0.00      1833\n",
            "          20       0.00      0.00      0.00       395\n",
            "          21       0.00      0.00      0.00       167\n",
            "\n",
            "   micro avg       0.56      0.21      0.30     20056\n",
            "   macro avg       0.03      0.05      0.03     20056\n",
            "weighted avg       0.12      0.21      0.15     20056\n",
            " samples avg       0.56      0.25      0.33     20056\n",
            "\n",
            "CPU times: user 3.13 s, sys: 2.57 s, total: 5.7 s\n",
            "Wall time: 9.69 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-XRCF_wO54m"
      },
      "source": [
        "### Exp_4_Var_3 Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qztN9VfwnFN4",
        "outputId": "7078205b-853c-4184-e2e7-0729ccf03544"
      },
      "source": [
        "model_7 = OneVsRestClassifier(MultinomialNB(alpha=1), n_jobs=-1).fit(X_train_mima, y_train)\n",
        "\n",
        "# export the model\n",
        "joblib.dump(model_7, '/content/drive/MyDrive/Colab Files/MGP/Trained Models/TFIDF_min_max/MNB_mima.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_train_model_7 = model_7.predict(X_train_mima)\n",
        "y_pred_model_7 = model_7.predict(X_test_mima)\n",
        "\n",
        "# Check overall accuracies\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# train_acc = accuracy_score(y_train, y_train_model_1)\n",
        "# test_acc = accuracy_score(y_test, y_pred_model_1)\n",
        "# train_scores.append(train_acc)\n",
        "# test_scores.append(test_acc)\n",
        "\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
        "\n",
        "# Recall Score\n",
        "train_recall_score = recall_score(y_train, y_train_model_7, average='weighted')\n",
        "test_recall_score = recall_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Train Recall Score:',train_recall_score)\n",
        "print('Test Recall Score:',test_recall_score)\n",
        "\n",
        "# Precision Score\n",
        "train_precision_score = precision_score(y_train, y_train_model_7, average='weighted')\n",
        "test_precision_score = precision_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Train Precision Score:',train_precision_score)\n",
        "print('Test Precision Score:',test_precision_score)\n",
        "\n",
        "# F1 Score\n",
        "train_f1_score = f1_score(y_train, y_train_model_7, average='weighted')\n",
        "print('Train F1 Score:',train_f1_score)\n",
        "\n",
        "test_f1_score = f1_score(y_test, y_pred_model_7, average='weighted')\n",
        "print('Test F1 Score:',test_f1_score)\n",
        "\n",
        "# Classification Report\n",
        "train_classification_report= classification_report(y_test, y_pred_model_7)\n",
        "print(train_classification_report)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Recall Score: 0.4832327744258142\n",
            "Test Recall Score: 0.4426106900678101\n",
            "Train Precision Score: 0.7074829158767606\n",
            "Test Precision Score: 0.6672724992731439\n",
            "Train F1 Score: 0.5479590699648026\n",
            "Test F1 Score: 0.5053991466956003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.44      0.51      1349\n",
            "           1       0.59      0.27      0.37       867\n",
            "           2       0.48      0.05      0.09       258\n",
            "           3       0.49      0.15      0.23       376\n",
            "           4       0.66      0.51      0.58      2650\n",
            "           5       0.68      0.39      0.50      1240\n",
            "           6       0.73      0.45      0.55       334\n",
            "           7       0.71      0.78      0.74      4197\n",
            "           8       0.72      0.05      0.10       483\n",
            "           9       0.59      0.15      0.24       600\n",
            "          10       0.00      0.00      0.00        81\n",
            "          11       0.52      0.19      0.28       351\n",
            "          12       0.78      0.41      0.54      1003\n",
            "          13       0.80      0.22      0.34       465\n",
            "          14       0.86      0.03      0.05       219\n",
            "          15       0.52      0.17      0.26       685\n",
            "          16       0.65      0.38      0.48      1656\n",
            "          17       0.72      0.35      0.47       648\n",
            "          18       0.88      0.26      0.40       199\n",
            "          19       0.65      0.43      0.52      1833\n",
            "          20       0.71      0.45      0.55       395\n",
            "          21       0.92      0.14      0.25       167\n",
            "\n",
            "   micro avg       0.68      0.44      0.53     20056\n",
            "   macro avg       0.65      0.29      0.37     20056\n",
            "weighted avg       0.67      0.44      0.51     20056\n",
            " samples avg       0.64      0.50      0.52     20056\n",
            "\n",
            "CPU times: user 9.65 s, sys: 3.29 s, total: 12.9 s\n",
            "Wall time: 10.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf7GuGH-vkcH"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WruK0mSIwI-W"
      },
      "source": [
        "Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zHcEd6ctwIKH",
        "outputId": "87efe0e7-4453-48ed-ce5e-6266d32195df"
      },
      "source": [
        "results_std = pd.read_csv('/content/drive/MyDrive/Colab Files/MGP/Results/TFIDF min max/Standard Scaler_min_max.csv', index_col=0)\n",
        "results_std"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Precission Score</th>\n",
              "      <th>Test Recall Score</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Train Precission Score</th>\n",
              "      <th>Train Recall Score</th>\n",
              "      <th>Train F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.594320</td>\n",
              "      <td>0.501147</td>\n",
              "      <td>0.538982</td>\n",
              "      <td>0.765140</td>\n",
              "      <td>0.618054</td>\n",
              "      <td>0.677020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.713902</td>\n",
              "      <td>0.216045</td>\n",
              "      <td>0.233560</td>\n",
              "      <td>0.764186</td>\n",
              "      <td>0.229308</td>\n",
              "      <td>0.249047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Test Precission Score  ...  Train F1 Score\n",
              "Logistic Regression               0.594320  ...        0.677020\n",
              "SGD                               0.713902  ...        0.249047\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns9s15MZwMUO"
      },
      "source": [
        "Min Max Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "h8tyDfEkGmU2",
        "outputId": "4efc096a-e3af-4bb7-f7d5-c383d09c092b"
      },
      "source": [
        "results_mima = pd.read_csv('/content/drive/MyDrive/Colab Files/MGP/Results/TFIDF min max/Min Max Scaler_min_max.csv', index_col=0)\n",
        "results_mima"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Precission Score</th>\n",
              "      <th>Test Recall Score</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Train Precission Score</th>\n",
              "      <th>Train Recall Score</th>\n",
              "      <th>Train F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.677748</td>\n",
              "      <td>0.462405</td>\n",
              "      <td>0.530831</td>\n",
              "      <td>0.778086</td>\n",
              "      <td>0.526134</td>\n",
              "      <td>0.605359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stochastic Gradient Descent</th>\n",
              "      <td>0.116917</td>\n",
              "      <td>0.209264</td>\n",
              "      <td>0.150018</td>\n",
              "      <td>0.116557</td>\n",
              "      <td>0.209224</td>\n",
              "      <td>0.149711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.667272</td>\n",
              "      <td>0.442611</td>\n",
              "      <td>0.505399</td>\n",
              "      <td>0.707483</td>\n",
              "      <td>0.483233</td>\n",
              "      <td>0.547959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Test Precission Score  ...  Train F1 Score\n",
              "Logistic Regression                       0.677748  ...        0.605359\n",
              "Stochastic Gradient Descent               0.116917  ...        0.149711\n",
              "MultinomialNB                             0.667272  ...        0.547959\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSh5LwGO9Mnd"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "After comparing all the models above with their respective scores, it was found that Min Max scaling is better than Standard Scaling for our dataset.\n",
        "\n",
        "Among the models trained after Min Max scaling, Logistic Regression performed the best with the highest F1 score. \n",
        "\n",
        "We will now perform modeling on the Exp1_Var2 and find out the best results and then compare Exp1_Var1 and Exp1_Var2."
      ]
    }
  ]
}